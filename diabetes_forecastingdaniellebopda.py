# -*- coding: utf-8 -*-
"""Diabetes_ForecastingDanielleBopda.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vucweox2ce24-sm0Be4oWcY12n1lMGY1
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Load the dataset
data = pd.read_csv('pima-indians-diabetes.csv')

# Define target and predictor variables
target_column = 'class'
predictors = data.columns.drop(target_column)

# Handle missing values by replacing zeros with the mean of the column
data = data.replace(0, np.nan)
data = data.fillna(data.mean())

# Normalize the predictor variables
data[predictors] = data[predictors] / data[predictors].max()

# Encode the target variable
le = LabelEncoder()
data[target_column] = le.fit_transform(data[target_column])

# Split the data into training and testing sets
X = data[predictors].values
y = data[target_column].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

# Initialize and train the model
mlp = MLPClassifier(hidden_layer_sizes=(15, 15, 15), activation='relu', solver='adam', max_iter=2000)
mlp.fit(X_train, y_train)

# Predict on training and testing sets
predict_train = mlp.predict(X_train)
predict_test = mlp.predict(X_test)

# Evaluate the model
print('Training accuracy')
print(confusion_matrix(y_train, predict_train))
print(classification_report(y_train, predict_train))

print('Testing accuracy')
print(confusion_matrix(y_test, predict_test))
print(classification_report(y_test, predict_test))

# Modify the network architecture and re-evaluate
mlp = MLPClassifier(hidden_layer_sizes=(20, 20, 20), activation='relu', solver='adam', max_iter=5000)
mlp.fit(X_train, y_train)

predict_train = mlp.predict(X_train)
predict_test = mlp.predict(X_test)

print('Training accuracy with modified network')
print(confusion_matrix(y_train, predict_train))
print(classification_report(y_train, predict_train))

print('Testing accuracy with modified network')
print(confusion_matrix(y_test, predict_test))
print(classification_report(y_test, predict_test))

#load diabetes dataset from OpenML
#https://www.openml.org/d/37
#Pima Indians Diabetes Database
# Import the necessary function
from sklearn.datasets import fetch_openml
diabetes = fetch_openml(name='diabetes',  as_frame=True)
print(diabetes.frame.columns)
print(diabetes.frame.describe())
print(diabetes.details)

"""#Exploratory Analysis:
I described
the data including the source, the collection method, and variables. I performed exploratory analysis. Also, select a few key variables (including the target variable for supervised learning) and study their distributions using plots such as histograms, box plot, bar chart, etc.
"""

#Import necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml

# Load the dataset
diabetes = fetch_openml(name='diabetes', as_frame=True)
df = diabetes.frame

#Summary Statistics
print(df.describe())

#Handling Missing Values
# Assuming zeros are missing values for specific columns
df[['plas', 'pres', 'skin', 'insu', 'mass']] = df[['plas', 'pres', 'skin', 'insu', 'mass']].replace(0, df[['plas', 'pres', 'skin', 'insu', 'mass']].mean())

# Distribution Plots for individual features
for column in df.columns[:-1]:  # Excluding the target column 'class'
    plt.figure(figsize=(8, 4))
    sns.distplot(df[column]) # Use df here as well to be consistent
    plt.title(f'Distribution of {column}')
    plt.show()

# Correlation Heatmap
plt.figure(figsize=(12, 8))
# Select only numerical columns for correlation calculation
numerical_df = df.select_dtypes(include=['float', 'int'])
correlation_matrix = numerical_df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# Scatter Plots for pairs of features
sns.pairplot(df, hue='class', diag_kind='kde')  # Replace 'data' with 'df' as DataFrame
plt.show()

# Import required libraries
import numpy as np
import sklearn
from sklearn.neural_network import MLPClassifier

# Import model to divide data into training and testing sets
from sklearn.model_selection import train_test_split

target_column = ['class']
#derive the list of predictor column id's
predictors = list(set(list(diabetes.frame.columns))-set(target_column))
#standardize the predictors by diividing by the maximum
diabetes.frame[predictors] = diabetes.frame[predictors]/diabetes.frame[predictors].max()
#provide summary statistics for the dataframe
diabetes.frame.describe().transpose()

#Get rid of any rown with NA's
diabetes.frame = diabetes.frame.dropna()

#the input data
X = diabetes.frame[predictors].values
#the output data
y = diabetes.frame[target_column].values

#we encode target classes from strings to numbers as neural networks cannot require all numerical inputs and outputs
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

#divide data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)
print(X_train.shape); print(X_test.shape)

#import the neural network (aka multi-layer-perceptron library)
from sklearn.neural_network import MLPClassifier

#The network architecture will consist of 1 input layer that has as many input nodes as columns-1, 3 hidden layers of 20 nodes each,
# and an output layer with a node for each of the categories--and the network will choose the one with the highest score
mlp = MLPClassifier(hidden_layer_sizes=(15,15,15), activation='relu', solver='adam', max_iter=2000)
#mlp = MLPClassifier(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=5000)
#we train the network
mlp.fit(X_train,y_train)

#We predict the training set
predict_train = mlp.predict(X_train)
#we predict the test set
predict_test = mlp.predict(X_test)

from sklearn.metrics import classification_report,confusion_matrix

print('Training accuracy')
#we report the confusion matrix for the training set
print(confusion_matrix(y_train,predict_train))
#we report various accuracy statistics for the training set
print(classification_report(y_train,predict_train))

print('Testing accuracy')
#we report the confusion matrix for the test set
print(confusion_matrix(y_test,predict_test))
#we report various accuracy statistics for the test set
print(classification_report(y_test,predict_test))

"""#Now rerun but above change the network architecture to
#mlp = MLPClassifier(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=5000)
"""

#The network architecture will consist of 1 input layer that has as many input nodes as columns-1, 3 hidden layers of 20 nodes each,
# and an output layer with a node for each of the categories--and the network will choose the one with the highest score
#mlp = MLPClassifier(hidden_layer_sizes=(15,15,15), activation='relu', solver='adam', max_iter=2000)
mlp = MLPClassifier(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=5000)
#we train the network
mlp.fit(X_train,y_train)

#We predict the training set
predict_train = mlp.predict(X_train)
#we predict the test set
predict_test = mlp.predict(X_test)

print('Training accuracy')
#we report the confusion matrix for the training set
print(confusion_matrix(y_train,predict_train))
#we report various accuracy statistics for the training set
print(classification_report(y_train,predict_train))

print('Testing accuracy')
#we report the confusion matrix for the test set
print(confusion_matrix(y_test,predict_test))
#we report various accuracy statistics for the test set
print(classification_report(y_test,predict_test))

"""#Now I reran but I change above the network architecture to
#mlp = MLPClassifier(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=10000)
"""

#The network architecture will consist of 1 input layer that has as many input nodes as columns-1, 3 hidden layers of 20 nodes each,
# and an output layer with a node for each of the categories--and the network will choose the one with the highest score
mlp = MLPClassifier(hidden_layer_sizes=(15,15,15), activation='relu', solver='adam', max_iter=10000)
#mlp = MLPClassifier(hidden_layer_sizes=(20,20,20), activation='relu', solver='adam', max_iter=5000)
#we train the network
mlp.fit(X_train,y_train)

#We predict the training set
predict_train = mlp.predict(X_train)
#we predict the test set
predict_test = mlp.predict(X_test)

print('Training accuracy')
#we report the confusion matrix for the training set
print(confusion_matrix(y_train,predict_train))
#we report various accuracy statistics for the training set
print(classification_report(y_train,predict_train))

print('Testing accuracy')
#we report the confusion matrix for the test set
print(confusion_matrix(y_test,predict_test))
#we report various accuracy statistics for the test set
print(classification_report(y_test,predict_test))

"""#Model Architecture Summary:"""

from sklearn.neural_network import MLPClassifier

# Initialize the model with the best configuration found
mlp = MLPClassifier(hidden_layer_sizes=(20, 20, 20), activation='relu', solver='adam', max_iter=10000)
mlp.fit(X_train, y_train)

# Summarize the model architecture
print(f"Number of layers: {mlp.n_layers_}")
print(f"Number of outputs: {mlp.n_outputs_}")
print(f"Number of iterations: {mlp.n_iter_}")
print(f"Loss: {mlp.loss_}")

"""#Confusion Matrix and Classification Report:"""

from sklearn.metrics import classification_report, confusion_matrix

# Predict on the test set
predict_test = mlp.predict(X_test)

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, predict_test)
print("Confusion Matrix:")
print(conf_matrix)

# Classification Report
class_report = classification_report(y_test, predict_test)
print("Classification Report:")
print(class_report)

"""#Loss Curve:"""

# Plot the loss curve
plt.figure(figsize=(8, 6))
plt.plot(mlp.loss_curve_)
plt.title('Loss Curve')
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.show()

"""#Feature Importances:"""

from sklearn.inspection import permutation_importance

# Calculate permutation importances
perm_importance = permutation_importance(mlp, X_test, y_test)

# Plot feature importances
feature_names = predictors
plt.figure(figsize=(12, 6))
plt.bar(feature_names, perm_importance.importances_mean)
plt.title('Feature Importances')
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.show()